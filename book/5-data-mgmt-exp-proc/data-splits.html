
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>What are the various data split strategies? &#8212; AI Practitioner Handbook</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="What are some potential scenarios of bias, unfairness, data leakage in data splits? How can these be remedied?" href="data-splits-bias-fairness-leakage.html" />
    <link rel="prev" title="Is there a core structure for performing exploratory data analysis in a systematic way?" href="eda-generic.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-HBHP8472S2"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-HBHP8472S2');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/AISG(R) Horizontal Logo CMYK Full Colour.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">AI Practitioner Handbook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to AI Singaporeâ€™s AI Practitioner Handbook
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../1-pre-project-phase/overview.html">
   1. Pre-project Phase
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../1-pre-project-phase/business_challenge_2_ai_problem.html">
     How does the AI engineer translate the business challenge into an AI problem?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1-pre-project-phase/key_areas_in_data.html">
     What are the key areas to look out for in the data when framing the AI project?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1-pre-project-phase/technical_debt.html">
     What are the factors/considerations/criteria to consider that will reduce potential technical debt?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1-pre-project-phase/ai_readiness_assessment.html">
     What are some questions that an AI engineer can ask the client during pre-project scoping to assess their AI readiness?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../2-proj-mgmt-tech-lead/overview.html">
   2. Project Management &amp; Technical Leadership
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../2-proj-mgmt-tech-lead/principles.html">
     What kind of engineering principles can I set for my development team?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2-proj-mgmt-tech-lead/translate-technical-jargon.html">
     How might we simplify and translate technical jargon for a non-technical audience?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../3-collab-dev-platforms/overview.html">
   3. Collaborative Development Platforms
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../3-collab-dev-platforms/collaborative_ml.html">
     What are the platforms and their respective considerations required for collaborative ML development?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../3-collab-dev-platforms/repo-structure-setup.html">
     What are some considerations in setting up a project repository to facilitate collaboration and establish good coding practices among developers?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../4-lit-review/overview.html">
   4. Literature Review
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../4-lit-review/factors-to-consider-during-literature-review.html">
     What are some of the factors/questions that an AI Engineer should consider during literature review?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="overview.html">
   5. Data Management, Exploration &amp; Processing
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="data-mgmt.html">
     Which data storage options are suitable for the project?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="eda-generic.html">
     Is there a core structure for performing exploratory data analysis in a systematic way?
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     What are the various data split strategies?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="data-splits-bias-fairness-leakage.html">
     What are some potential scenarios of bias, unfairness, data leakage in data splits? How can these be remedied?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="e2e-workflow.html">
     What are the processes involved in building a basic end-to-end Workflow?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="e2e-workflow-adv.html">
     How do I enhance the workflow with quality-of-life improvements for my end-to-end workflow?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="data-poisoning-data-extraction.html">
     How can I reduce the risks of data poisoning and data extraction?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../6-modelling/overview.html">
   6. Modelling
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../6-modelling/eval-metrics.html">
     What are the considerations (internally by the team), and externally (by the stakeholders) when selecting evaluation metrics?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6-modelling/model-reproducibility.html">
     How can I maximise model reproducibility?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6-modelling/ml-risks-and-robustness.html">
     What are some ML risks I should be aware of? How do ML risks relate to model robustness? What are some tools I can use to assess model robustness?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6-modelling/evaluating-timeseries.html">
     How can we better evaluate time-series classification models?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6-modelling/post-hoc-explanation.html">
     How can we provide a simple post-hoc explanation for black-box model performance to ensure reliability?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../7-solution-delivery/overview.html">
   7. Solution Delivery
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../7-solution-delivery/deployment-requirements-gathering.html">
     What are some questions to be asked to the project sponsor to understand their deployment requirements?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../7-solution-delivery/min-viable-code.html">
     How can we build a minimum viable code/configuration for CI/CD automation into an existing codebase?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../8-documentation-handover/overview.html">
   8. Documentation &amp; Handover
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../8-documentation-handover/documenting-architecture-processes.html">
     What are some good practices in documenting high-level system architecture and processes of an AI solution?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../_contributing.html">
   How To Contribute
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../markdown-template.html">
     How should I write a section using Markdown?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../notebook-template.html">
     How should I write a section using Jupyter notebooks?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../REVIEWING.html">
     How do I review content?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../cite.html">
   Cite This Book
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../_changelog.html">
   Change Log
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/aimakerspace/ai-practitioner-handbook"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/aimakerspace/ai-practitioner-handbook/issues/new?title=Issue%20on%20page%20%2Fbook/5-data-mgmt-exp-proc/data-splits.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/book/5-data-mgmt-exp-proc/data-splits.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#static-train-test-split">
   1. Static train-test Split
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-set">
     Train set
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#validation-set">
     Validation set
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#test-set">
     Test set
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#split-ratio">
     Split ratio
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cross-validation">
   2. Cross-validation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nested-cross-validation">
   3. Nested cross-validation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stratified-split">
   4. Stratified Split
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#temporal-split">
   5. Temporal Split
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>What are the various data split strategies?</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#static-train-test-split">
   1. Static train-test Split
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-set">
     Train set
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#validation-set">
     Validation set
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#test-set">
     Test set
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#split-ratio">
     Split ratio
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cross-validation">
   2. Cross-validation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nested-cross-validation">
   3. Nested cross-validation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stratified-split">
   4. Stratified Split
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#temporal-split">
   5. Temporal Split
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="what-are-the-various-data-split-strategies">
<h1>What are the various data split strategies?<a class="headerlink" href="#what-are-the-various-data-split-strategies" title="Permalink to this headline">#</a></h1>
<p>Contributor(s): Lee Xin Jie, Senior AI Engineer (100E)</p>
<section id="static-train-test-split">
<h2>1. Static train-test Split<a class="headerlink" href="#static-train-test-split" title="Permalink to this headline">#</a></h2>
<p>The most common train test split strategy is to create static training, validation and test data sets.</p>
<section id="train-set">
<h3>Train set<a class="headerlink" href="#train-set" title="Permalink to this headline">#</a></h3>
<p>The train set is the subset of the data that will be used to train the ML model. The modelâ€™s performance on the train set will only provide an indication of how well the model will perform on previously seen data.</p>
</section>
<section id="validation-set">
<h3>Validation set<a class="headerlink" href="#validation-set" title="Permalink to this headline">#</a></h3>
<p>The validation set, also commonly referred to as the development set, consists of data that is unseen during model training. It provides an estimation of the modelâ€™s performance during production.  The validation set is often used during model hyperparameter tuning and algorithm selection. When performing algorithm selection, it is important to ensure that the validation set used is the same across all algorithms to ensure a fair comparison.</p>
</section>
<section id="test-set">
<h3>Test set<a class="headerlink" href="#test-set" title="Permalink to this headline">#</a></h3>
<p>The test set is the second hold-out set that will not be used during training. Since the validation set is commonly used to influence the modelling decisions, our ML model pipeline is likely to be biased in performing well on the validation set. Hence, we will need a completely unseen set of data to provide a final benchmark of our modelâ€™s performance on unseen data. It is important to not use this test set to influence your modelling decision. Otherwise you will get an inflated sense of how well the model will perform in real life. You should only evaluate your model on the test set during the final step of the pipeline. As such, it is common for the train set performance to be higher than the validation performance, which in turn, should be higher than the test performance.</p>
<p><strong>Tip</strong>: After finding the best model from validation, it is also good practice to re-run this model (with the best hyperparameters) on the full dataset (train + validation + test) and save the resulting weights for further use.</p>
</section>
<section id="split-ratio">
<h3>Split ratio<a class="headerlink" href="#split-ratio" title="Permalink to this headline">#</a></h3>
<p>There is no single â€˜goldenâ€™ data splitting proportion. In general, the larger your dataset, the lower the proportion of data you have to set aside for the validation and test sets. If you have a dataset with a billion data points, you could theoretically set aside 1% of the data for the test set, and still have a sufficiently large test set of 10 million data points. Conversely, the smaller your dataset, the larger the proportion of data that should be set aside for your validation and test sets. This will allow you to have a more confident estimation of model performance during production, as your modelâ€™s performance will be determined on a larger and more diverse validation/test set.</p>
<p>One commonly used rule of thumb will be to adopt a 70-20-10 split for your train, validation and test sets respectively. Ultimately, you should prioritise selecting a ratio catered to your needs.</p>
</section>
</section>
<section id="cross-validation">
<h2>2. Cross-validation<a class="headerlink" href="#cross-validation" title="Permalink to this headline">#</a></h2>
<p>A single, static validation set could potentially present a biased assessment of model performance. This is particularly the case with smaller datasets where favourable validation performance may arise by chance.</p>
<p>Cross-validation is an alternative to having a static validation set. In cross-validation, you will conduct multiple rounds of model training, each time with a different section of your dataset serving as the validation set. This will minimise the variance associated with choosing any particular choice of validation set. However, cross-validation does come with the penalty of additional training time. The difference could be significant especially when training large models. So it is usually recommended when you are dealing with a smaller dataset where there could be insufficient samples to form a reliable validation set. In such cases, favourable validation performance may arise by chance due to a higher proportion of â€˜easierâ€™ examples appearing in the validation set, hence the need for cross-validation.</p>
</section>
<section id="nested-cross-validation">
<h2>3. Nested cross-validation<a class="headerlink" href="#nested-cross-validation" title="Permalink to this headline">#</a></h2>
<p>While cross-validation reduces the amount of overfitting as compared to the use of a static train test split, it does not reduce it completely. This is because the same score is used to select the best model and to evaluate the model.</p>
<p>To overcome it, you may choose to use nested cross-validation, which will seperate the score used to select the best model and to evalute the model. In this approach, the outer loop is used mainly for model evaluation, while the inner loop is used for hyperparameter tuning.</p>
<p>To illustrate this, let us assume you are using an outer fold of 3, and an inner fold of 3, and you are tuning and evaluating for the parameter <em>n</em> for a model. For the outer loop, you will split the dataset into 3 folds, and rotate the test fold for each set.</p>
<p><img alt="Outer Split" src="../../_images/nested-outer-fold.png" /></p>
<p>Taking the first training set, you will further split it into 3 folds with 1 fold serving as the validation set.</p>
<p><img alt="Inner Split" src="../../_images/nested-inner-fold.png" /></p>
<p>You will train a model with a value of <em>n</em>, say <em>n=1</em>, on the training folds, and evaluate the model on the validation fold. You repeat the model training with the same <em>n=1</em> value each time you rotate the validation fold. The mean of the scores across all validation folds will be the validation score for the paramater <em>n=1</em>. You will repeat this procedure for all other <em>n</em> values, and then select the best <em>n</em> value.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Train</p></th>
<th class="head"><p>Test</p></th>
<th class="head"><p>n</p></th>
<th class="head"><p>Val Acc</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Inn2,Inn3</p></td>
<td><p>Inn1</p></td>
<td><p>1</p></td>
<td><p>92</p></td>
</tr>
<tr class="row-odd"><td><p>Inn1,Inn3</p></td>
<td><p>Inn2</p></td>
<td><p>1</p></td>
<td><p>90</p></td>
</tr>
<tr class="row-even"><td><p>Inn1,Inn2</p></td>
<td><p>Inn3</p></td>
<td><p>1</p></td>
<td><p>88</p></td>
</tr>
<tr class="row-odd"><td><p>Inn2,Inn3</p></td>
<td><p>Inn1</p></td>
<td><p>2</p></td>
<td><p>80</p></td>
</tr>
<tr class="row-even"><td><p>Inn1,Inn3</p></td>
<td><p>Inn2</p></td>
<td><p>2</p></td>
<td><p>83</p></td>
</tr>
<tr class="row-odd"><td><p>Inn1,Inn2</p></td>
<td><p>Inn3</p></td>
<td><p>2</p></td>
<td><p>77</p></td>
</tr>
</tbody>
</table>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>n</p></th>
<th class="head"><p>Mean Val Acc</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>90</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>80</p></td>
</tr>
</tbody>
</table>
<p>Finally, you will train on the full training and validation set with this best <em>n</em> parameter, and evaluate on the test set that was set aside intially in the outer fold.</p>
<p>You repeat the same procedure for all iterations of the outer loop, to obtain the final evaluation of the model.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Train</p></th>
<th class="head"><p>Test</p></th>
<th class="head"><p>Best n</p></th>
<th class="head"><p>Test Acc</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Out2,Out3</p></td>
<td><p>Out1</p></td>
<td><p>1</p></td>
<td><p>92</p></td>
</tr>
<tr class="row-odd"><td><p>Out1,Out3</p></td>
<td><p>Out2</p></td>
<td><p>2</p></td>
<td><p>84</p></td>
</tr>
<tr class="row-even"><td><p>Out1,Out2</p></td>
<td><p>Out3</p></td>
<td><p>1</p></td>
<td><p>88</p></td>
</tr>
<tr class="row-odd"><td><p>Mean test accuracy: 88</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p>If you want to configure the best model, one possible option is to ensemble all the best inner models.</p>
<p>The drawback of the nested cross-validation approach is that the training time will even be longer than the standard cross-validation.</p>
<p><strong>Tip</strong>: In cases of extremely small datasets, you could consider <em>nested cross-validation</em> to maximise the usage of the whole dataset for training, validation and testing.</p>
</section>
<section id="stratified-split">
<h2>4. Stratified Split<a class="headerlink" href="#stratified-split" title="Permalink to this headline">#</a></h2>
<p>For datasets with unbalanced distribution of targets and/or features, you may want to consider stratified splitting. Stratified splitting aims to split your dataset, while maintaining similar proportions of any desired features/targets across your train, validation and test sets.</p>
<p>An example of a dataset with features that are skewed in their distribution will be a credit worthiness classification problem, where you may have fewer individuals in the dataset with ages of less than 20 years old.  A random split could result in insufficient numbers of them getting assigned to the validation and test sets. If it is critical to model the behaviour of this age group, you can stratify the dataset based on age buckets. Doing so would fix the proportion of each age group getting assigned to each set.</p>
<p>An example of a dataset with imbalanced targets will be a fraud detection dataset, where fraudulent examples are typically the minority. In this case, you will stratify the dataset based on the target.</p>
<p>In general, the larger the dataset, the less likely features and targets will be unevenly distributed across the sets. You should still check your dataset for any uneven distribution in features and targets.</p>
</section>
<section id="temporal-split">
<h2>5. Temporal Split<a class="headerlink" href="#temporal-split" title="Permalink to this headline">#</a></h2>
<p>When you are dealing with problems related to forecasting future values, you may want to consider temporal splitting. As an example, assume you have data from January to April. You may want to set aside data from January to February for your training dataset, March for your validation dataset, and April for your test dataset.</p>
<p>In fast moving environments such as fraud detection and cyber attack classification, bad actors might develop new fraud and cyber attacks techniques. It may be necessary to continuously train the model on the latest data to predict future frauds and cyber attacks, even though the task does not involve forecasting. Evaluating the model on historical frauds and attacks may be insufficient. Hence, you may choose to consider temporal splitting in this scenario.</p>
<p>In scenarios where there are high correlations between successive times, such as in weather forecasting, you will also want to consider temporal splits and avoid placing February 1 in the training set and February 2 in the validation set to minimise data leakage.</p>
<p>For seasonal data, you may want to take seasonality into account when performing temporal splits. As an example, you can place the first 20 days of every month into the training set, the next 5 days into the validation set, and the last 5 days in the test set.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.oreilly.com/library/view/building-machine-learning/9781492045106/">Building Machine Learning Powered Applications: Going from Idea to Product</a></p></li>
<li><p><a class="reference external" href="https://www.oreilly.com/library/view/machine-learning-design/9781098115777/">Machine Learning Design Patterns: Solutions to Common Challenges in Data Preparation, Model Building, and MLOps</a></p></li>
<li><p><a class="reference external" href="https://www.deeplearning.ai/courses/">Machine Learning Yearning: Technical Strategy for AI Engineers, In the Era of Deep Learning</a></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./book/5-data-mgmt-exp-proc"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="eda-generic.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Is there a core structure for performing exploratory data analysis in a systematic way?</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="data-splits-bias-fairness-leakage.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">What are some potential scenarios of bias, unfairness, data leakage in data splits? How can these be remedied?</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By AI Singapore<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>